<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  
  <title>概率语言模型：Naive | 一切可以触摸到的都是代码</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
  
    <meta name="author" content="oldwang">
  
  
    <meta name="description" content="Naive的概率语言模型实现上一节，引出概率语言模型的时候给出的计算句子出现的概率的公式：计算句子的概率：P(S)=P(w1,w2,w3,…,wn)
在对公式进行拆解的时候，有：P(w1w2)=P(w2|w1)*P(w1)在此基础上，进行粗糙的假设：P(w2|w2)≈P(w2)">
  
  <meta name="description" content="Naive的概率语言模型实现上一节，引出概率语言模型的时候给出的计算句子出现的概率的公式：计算句子的概率：P(S)=P(w1,w2,w3,…,wn)
在对公式进行拆解的时候，有：P(w1w2)=P(w2|w1)*P(w1)在此基础上，进行粗糙的假设：P(w2|w2)≈P(w2)">
<meta property="og:type" content="article">
<meta property="og:title" content="概率语言模型：Naive">
<meta property="og:url" content="https://minikui.github.io/2017/03/12/概率语言模型：Naive/index.html">
<meta property="og:site_name" content="一切可以触摸到的都是代码">
<meta property="og:description" content="Naive的概率语言模型实现上一节，引出概率语言模型的时候给出的计算句子出现的概率的公式：计算句子的概率：P(S)=P(w1,w2,w3,…,wn)
在对公式进行拆解的时候，有：P(w1w2)=P(w2|w1)*P(w1)在此基础上，进行粗糙的假设：P(w2|w2)≈P(w2)">
<meta property="og:updated_time" content="2017-03-12T08:45:31.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="概率语言模型：Naive">
<meta name="twitter:description" content="Naive的概率语言模型实现上一节，引出概率语言模型的时候给出的计算句子出现的概率的公式：计算句子的概率：P(S)=P(w1,w2,w3,…,wn)
在对公式进行拆解的时候，有：P(w1w2)=P(w2|w1)*P(w1)在此基础上，进行粗糙的假设：P(w2|w2)≈P(w2)">
  
    <link rel="alternate" href="/atom.xml" title="一切可以触摸到的都是代码" type="application/atom+xml">
  
  
    <link rel="icon" type="image/x-icon" href="/favicon.ico">
  
  <link rel="stylesheet" href="/css/style.css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  
<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-80534708-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>

</head>

<body>
  <div class="wrapper">
    <header id="header">
  <div class="title">
    <h1><a href="/">一切可以触摸到的都是代码</a></h1>
    <p><a href="/">coding writing ...</a></p>
  </div>
  <nav class="nav">
    <ul>
      
        <li><a href="/">Home</a></li>
      
        <li><a href="/archives">Archives</a></li>
      
        <li><a href="/about">About</a></li>
      
      
        <li><a href="/atom.xml">RSS</a></li>
      
    </ul>
    <div class="clearfix"></div>
  </nav>
  <div class="clearfix"></div>
</header>
    <div class="content"><article class="post">
  <header>
    
      <div class="icon"></div>
      <a href="/2017/03/12/概率语言模型：Naive/">
  <time datetime="2017-03-12T08:32:16.000Z">
    2017-03-12
  </time>
</a>
    
    
  
    <h1 class="title">概率语言模型：Naive</h1>
  

  </header>
  
  <div class="entry">
    
      <h2 id="Naive的概率语言模型实现"><a href="#Naive的概率语言模型实现" class="headerlink" title="Naive的概率语言模型实现"></a>Naive的概率语言模型实现</h2><p>上一节，引出概率语言模型的时候给出的计算句子出现的概率的公式：<br>计算句子的概率：<strong>P(S)=P(w1,w2,w3,…,wn)</strong></p>
<p>在对公式进行拆解的时候，有：<br><strong>P(w1w2)=P(w2|w1)*P(w1)</strong><br>在此基础上，进行粗糙的假设：<strong>P(w2|w2)≈P(w2)</strong><br><a id="more"></a><br>这里的假设很Naive，舍弃了很多，最终得到的肯定和理想偏差很多，可是我们可以从这样的公式里面得到后面对N-gram模型的构建。<br>假设以后，上面的计算句子概率公式变成：<br><strong>P(S)=P(w1)P(w2)…P(wn)</strong>，既是每一个词同时出现的概率。</p>
<hr>
<p>直接上代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">s = float(sum(l_model.values()))</div><div class="line">for key, cnt in l_model.items():</div><div class="line">    l_model[key] /= s</div></pre></td></tr></table></figure></p>
<p>这一段是计算一份语料里面每一个词出现的频率，其中：<strong>l_model</strong>既是Naive的语言模型，里面统计的是每一个词出现的频次。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">def generate(l_model):</div><div class="line">    r = random.random()</div><div class="line">    s = 0.0</div><div class="line">    for (word, prob) in l_model.most_common():</div><div class="line">        s += prob</div><div class="line">        if s &gt;= r:</div><div class="line">            return word</div></pre></td></tr></table></figure></p>
<p>定义一个生成器，设置一个随机数做这里的阈值，达到这个阈值，表示随机抽样抽中了，直接return。</p>
<p>这里的模型比较Naive，得到的语言模型基本上不通。<br>下一节介绍<strong>N-gram模型</strong>的学习</p>

    
  </div>
  <footer>
    
      
  <div class="categories">
    <a class="categories-link" href="/categories/NLP/">NLP</a>
  </div>

      
  <div class="tags">
    <a class="tags-link" href="/tags/Naive/">Naive</a>, <a class="tags-link" href="/tags/概率/">概率</a>, <a class="tags-link" href="/tags/模型/">模型</a>, <a class="tags-link" href="/tags/自然语言/">自然语言</a>
  </div>

    
    <div class="clearfix"></div>
  </footer>
</article>

</div>
  </div>
  <footer id="footer"><div class="copyright">
  
  &copy; 2017 <a href="/">oldwang</a>
  
</div>
<div class="theme-copyright">
  Theme by <a href="https://github.com/orderedlist" target="_blank">orderedlist</a>
   | 
  Redesign by <a href="http://heroicyang.com/" target="_blank">Heroic Yang</a>
</div>
<div class="clearfix"></div></footer>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.8/jquery.min.js"></script>
<script src="/js/scale.fix.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>




<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
  (function($){
    $('.fancybox').fancybox();
  })(jQuery);
</script>

</body>
</html>